{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12780451",
   "metadata": {},
   "source": [
    "# Unsupervised gridsearch\n",
    "This notebook executed the unsupervised gridsearch using Dask and our own 'affe' (another framework for experimentation) helper framework for experimentation.  \n",
    "In this notebook you'll also find a few helper methods to generate config files for the gridsearch.  \n",
    "However, you can also makes these files manually.  \n",
    "Just ensure that in each of the following notebooks is using the correct version of the gridsearch.  \n",
    "*note: the experiments are ran for way more datasets than actually used in the final results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to autoreload code changes, for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12a82f-280e-4618-87e4-12ba8ae2b557",
   "metadata": {},
   "source": [
    "## Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d514f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ODD.workflows.experiment_config import execute_experiment, ConfigBuilder\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89116e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = Path()/'config'\n",
    "result_dir = Path()/'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac17a3f-382a-45de-9337-e8e6adbba477",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = \"domain_to_dask_scheduler.com:8786\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f6dc2-f7b7-4be9-9ce4-4785878ae72c",
   "metadata": {},
   "source": [
    "### Helper for generating config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gs_config(config_path, algo, parameter_dict): \n",
    "    (\n",
    "        ConfigBuilder(config_path.stem, root_levels_up = 2, timeout_s= 3600)\n",
    "        .add_dataset('campos', datasets ='all', versions = [1], anomaly_fraction = [-1,2,5,10])\n",
    "        .add_algorithm(algo, f'{algo}_grid', **parameter_dict)\n",
    "        .to_file(config_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1981ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_dict = dict(\n",
    "    LOF = dict(\n",
    "        n_neighbors = list(range(1,300,2))\n",
    "    ), \n",
    "    KNN = dict(\n",
    "        n_neighbors = list(range(1,300,2))\n",
    "    ), \n",
    "    HBOS = dict(\n",
    "        n_bins = list(range(5, 101,5))\n",
    "    ), \n",
    "    IForest = dict(\n",
    "        n_estimators = list(range(25,301,25)), \n",
    "        max_samples = list(np.arange(0.1,1.01,0.1)), \n",
    "        max_features = list(np.arange(0.1,1.01, 0.1))\n",
    "    ), \n",
    "    CBLOF = dict(\n",
    "        n_clusters = list(range(2,50, 2)), \n",
    "        alpha = list(np.arange(0.5,0.99,0.1)), \n",
    "        beta = list(range(2, 21, 2)), \n",
    "        use_weights = [False, True]\n",
    "    ), \n",
    "    OCSVM = dict(\n",
    "        kernel = ['rbf'], \n",
    "        nu = list(np.linspace(0.02,1,50)), \n",
    "        gamma = [ 0.001, 0.005, 0.01, 0.05, 0.1,0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0, 5000.0, 10000.0]\n",
    "    )\n",
    ")\n",
    "version_dict = defaultdict(lambda : 1)\n",
    "version_dict['HBOS'] = 2\n",
    "version_dict['IForest'] = 2\n",
    "version_dict['CBLOF'] = 2 \n",
    "version_dict['OCSVM'] = 3\n",
    "\n",
    "for algo, parameter_dict in setup_dict.items(): \n",
    "    version = version_dict[algo]\n",
    "    file_name = f\"grid_{algo}_v{version}.toml\"\n",
    "    config_path = config_dir/file_name\n",
    "    if not config_path.exists():\n",
    "        make_gs_config(config_path, algo, parameter_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37e4af-b768-454c-84b4-9f1bbc825710",
   "metadata": {},
   "source": [
    "## Run the gridsearch using the generated config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8111939",
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo in setup_dict.keys(): \n",
    "    version = version_dict[algo]\n",
    "    config_name = f\"grid_{algo}_v{version}.toml\"\n",
    "    result_name = f\"grid_{algo}_v{version}.pkl\"\n",
    "    execute_experiment(config_dir/config_name, result_dir/result_name, dask_scheduler = scheduler, shuffle = True, progress = False, dask_batch_size = 25)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
